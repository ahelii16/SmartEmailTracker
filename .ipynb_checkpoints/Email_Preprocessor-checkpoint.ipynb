{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. How to work with emoji package\n",
    "#2. How to process csv files or custom datasets(not keras dataset)\n",
    "#3. How to use transfer learning\n",
    "#4. Build an LSTM model\n",
    "#5. Stacked LSTM\n",
    "#6. Predictions (i/p: sentence  o/p: most suitable emoji)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, email,re\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns; sns.set_style('whitegrid')\n",
    "\n",
    "# NLP\n",
    "from nltk.tokenize.regexp import RegexpTokenizer\n",
    "from subprocess import check_output\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import string\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(301, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>From</th>\n",
       "      <th>To</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Body</th>\n",
       "      <th>Class(output)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Morgan@JPMorgan.com</td>\n",
       "      <td>Esabella@CitiBankSingapore.com</td>\n",
       "      <td>168717Waiting for amount pending</td>\n",
       "      <td>The trasaction 168717 is taking too long to be...</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Morgan@HSBC.com</td>\n",
       "      <td>Meghan@CitiBankLondon.com</td>\n",
       "      <td>413891Transaction is in progress</td>\n",
       "      <td>Payment 413891 will be completed within two days</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Morgan@CitiBankLondon.com</td>\n",
       "      <td>Anthony@CitiBankLondon.com</td>\n",
       "      <td>988795urgent: need transaction details</td>\n",
       "      <td>988795 sdjvbksd</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Morgan@CitiBankLondon.com</td>\n",
       "      <td>Dipesh@CitiBankLondon.com</td>\n",
       "      <td>613137Transaction Failed</td>\n",
       "      <td>Lack of funds, check no. 613137 has been bounced.</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        From                              To  \\\n",
       "0                        NaN                             NaN   \n",
       "1        Morgan@JPMorgan.com  Esabella@CitiBankSingapore.com   \n",
       "2            Morgan@HSBC.com       Meghan@CitiBankLondon.com   \n",
       "3  Morgan@CitiBankLondon.com      Anthony@CitiBankLondon.com   \n",
       "4  Morgan@CitiBankLondon.com       Dipesh@CitiBankLondon.com   \n",
       "\n",
       "                                  Subject  \\\n",
       "0                                     NaN   \n",
       "1        168717Waiting for amount pending   \n",
       "2        413891Transaction is in progress   \n",
       "3  988795urgent: need transaction details   \n",
       "4                613137Transaction Failed   \n",
       "\n",
       "                                                Body Class(output)  \n",
       "0                                                NaN           NaN  \n",
       "1  The trasaction 168717 is taking too long to be...             B  \n",
       "2   Payment 413891 will be completed within two days             B  \n",
       "3                                    988795 sdjvbksd             D  \n",
       "4  Lack of funds, check no. 613137 has been bounced.             A  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# emails_df = pd.read_csv('./emails.csv', nrows=20000)\n",
    "df = pd.read_csv('./emaildataset.csv')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[1:]\n",
    "df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>From</th>\n",
       "      <th>To</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Body</th>\n",
       "      <th>Class(output)</th>\n",
       "      <th>text_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Morgan@JPMorgan.com</td>\n",
       "      <td>Esabella@CitiBankSingapore.com</td>\n",
       "      <td>168717Waiting for amount pending</td>\n",
       "      <td>The trasaction 168717 is taking too long to be...</td>\n",
       "      <td>B</td>\n",
       "      <td>168717Waiting for amount pendingThe trasaction...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Morgan@HSBC.com</td>\n",
       "      <td>Meghan@CitiBankLondon.com</td>\n",
       "      <td>413891Transaction is in progress</td>\n",
       "      <td>Payment 413891 will be completed within two days</td>\n",
       "      <td>B</td>\n",
       "      <td>413891Transaction is in progressPayment 413891...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Morgan@CitiBankLondon.com</td>\n",
       "      <td>Anthony@CitiBankLondon.com</td>\n",
       "      <td>988795urgent: need transaction details</td>\n",
       "      <td>988795 sdjvbksd</td>\n",
       "      <td>D</td>\n",
       "      <td>988795urgent: need transaction details 988795 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Morgan@CitiBankLondon.com</td>\n",
       "      <td>Dipesh@CitiBankLondon.com</td>\n",
       "      <td>613137Transaction Failed</td>\n",
       "      <td>Lack of funds, check no. 613137 has been bounced.</td>\n",
       "      <td>A</td>\n",
       "      <td>613137Transaction FailedLack of funds, check n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Spike@BNYMellon.com</td>\n",
       "      <td>Meghan@CitiBankNewYork.com</td>\n",
       "      <td>Update on Acc 131265</td>\n",
       "      <td>The trasaction 131265 is taking too long to be...</td>\n",
       "      <td>B</td>\n",
       "      <td>Update on Acc 131265The trasaction 131265 is t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        From                              To  \\\n",
       "0        Morgan@JPMorgan.com  Esabella@CitiBankSingapore.com   \n",
       "1            Morgan@HSBC.com       Meghan@CitiBankLondon.com   \n",
       "2  Morgan@CitiBankLondon.com      Anthony@CitiBankLondon.com   \n",
       "3  Morgan@CitiBankLondon.com       Dipesh@CitiBankLondon.com   \n",
       "4        Spike@BNYMellon.com      Meghan@CitiBankNewYork.com   \n",
       "\n",
       "                                  Subject  \\\n",
       "0        168717Waiting for amount pending   \n",
       "1        413891Transaction is in progress   \n",
       "2  988795urgent: need transaction details   \n",
       "3                613137Transaction Failed   \n",
       "4                    Update on Acc 131265   \n",
       "\n",
       "                                                Body Class(output)  \\\n",
       "0  The trasaction 168717 is taking too long to be...             B   \n",
       "1   Payment 413891 will be completed within two days             B   \n",
       "2                                    988795 sdjvbksd             D   \n",
       "3  Lack of funds, check no. 613137 has been bounced.             A   \n",
       "4  The trasaction 131265 is taking too long to be...             B   \n",
       "\n",
       "                                           text_data  \n",
       "0  168717Waiting for amount pendingThe trasaction...  \n",
       "1  413891Transaction is in progressPayment 413891...  \n",
       "2  988795urgent: need transaction details 988795 ...  \n",
       "3  613137Transaction FailedLack of funds, check n...  \n",
       "4  Update on Acc 131265The trasaction 131265 is t...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Class'] = df['Class(output)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['index'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Payment 413891 will be completed within two days\n"
     ]
    }
   ],
   "source": [
    "print(df.loc[1][\"Body\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    stop = set(stopwords.words('english'))\n",
    "    stop.update((\"to\",\"cc\",\"subject\",\"http\",\"from\",\"sent\",\"thanks\", \"regards\", \"hi\", \"hello\", \"thank you\"))\n",
    "    exclude = set(string.punctuation) \n",
    "    lemma = WordNetLemmatizer()\n",
    "    porter= PorterStemmer()\n",
    "    \n",
    "    text=text.rstrip()\n",
    "    text = re.sub(r'[^a-zA-Z]', ' ', text)\n",
    "    amount = \" \".join([i for i in text.lower().split() if i.isdigit()])\n",
    "    stop_free = \" \".join([i for i in text.lower().split() if((i not in stop) and (not i.isdigit()))])\n",
    "    punc_free = ''.join(ch for ch in stop_free if ch not in exclude)\n",
    "    normalized = \" \".join(lemma.lemmatize(word) for word in punc_free.split())\n",
    "    stem = \" \".join(porter.stem(token) for token in normalized.split())\n",
    "    \n",
    "    return normalized, amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sub_df[\"content\"]=sub_df[\"content\"].map(clean)\n",
    "text_clean=[]\n",
    "\n",
    "for text in df['Body']:\n",
    "    text_clean.append(clean(text)[0].split())\n",
    "    amount = clean(text)[1]\n",
    "\n",
    "amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_dictionary = {\"1\": \"Transaction complete\",\n",
    "                    \"2\": \"Waiting for pending amount\",\n",
    "                    \"3\": \"Payment Failed\",\n",
    "                    \"4\": \"Payment is in progress\",\n",
    "                   }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we are going to use these 5 classes for sentiment analysis o/p (5 o/p classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Processing a custom dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print the sentences with emojis\n",
    "data = df.values\n",
    "for i in range(df.shape[0]):\n",
    "    # merge subject and body strings\n",
    "    df['text_data'] = df['Subject'] + \" \" + df['Body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert sentences to embeddings and classes to one-hot vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400000\n"
     ]
    }
   ],
   "source": [
    "embeddings = {}\n",
    "with open('../data_science_CB/Machine-learning-online-2018-master/17. Word2Vec/glove.6B.50d.txt',encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coeffs = np.asarray(values[1:],dtype='float32')\n",
    "        \n",
    "#         print(word)\n",
    "#         print(coeffs)\n",
    "        embeddings[word] = coeffs\n",
    "    f.close()\n",
    "print(len(embeddings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 - Converting sentences to vectors (creating the o/p of embedding layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOutputEmbeddings(X):\n",
    "    \n",
    "    #let 10 is max len of sentence, 50 batch size (no. of e.g.)\n",
    "    embedding_matrix_output = np.zeros((X.shape[0],100,50))\n",
    "    \n",
    "    for ix in range(X.shape[0]):\n",
    "        X[ix] = X[ix].split()\n",
    "        for jx in range(len(X[ix])):\n",
    "            #go to every word in current(ix) sentence\n",
    "            embedding_matrix_output[ix][jx] = embeddings[X[ix][jx].lower()]\n",
    "            \n",
    "    return embedding_matrix_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'B'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-a3712692dbd7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mXT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text_data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mYT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Class'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m# Yt = to_categorical(test[1], num_classes=5)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/utils/np_utils.py\u001b[0m in \u001b[0;36mto_categorical\u001b[0;34m(y, num_classes, dtype)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \"\"\"\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'int'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m     \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    752\u001b[0m               dtype='datetime64[ns]')\n\u001b[1;32m    753\u001b[0m         \"\"\"\n\u001b[0;32m--> 754\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m     \u001b[0;31m# ----------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m     \"\"\"\n\u001b[0;32m--> 538\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/arrays/numpy_.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0m_HANDLED_TYPES\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumbers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m     \"\"\"\n\u001b[0;32m--> 538\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: 'B'"
     ]
    }
   ],
   "source": [
    "XT = df['text_data']\n",
    "\n",
    "YT = to_categorical(df['Class'], num_classes=4)\n",
    "# Yt = to_categorical(test[1], num_classes=5)\n",
    "\n",
    "print(XT[0])\n",
    "print(XT.shape)\n",
    "print(Xt.shape)\n",
    "# print(YT.shape)\n",
    "# print(Yt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['never', 'talk', 'to', 'me', 'again']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aheli/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "embed_matrix_train = getOutputEmbeddings(XT)\n",
    "embed_matrix_test = getOutputEmbeddings(Xt)\n",
    "\n",
    "print(XT[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132, 10, 50)\n",
      "(56, 10, 50)\n"
     ]
    }
   ],
   "source": [
    "print(embed_matrix_train.shape)\n",
    "print(embed_matrix_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Define RNN/LSTM model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import *\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_5 (LSTM)                (None, 10, 64)            29440     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 10, 64)            0         \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 325       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 62,789\n",
      "Trainable params: 62,789\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(64,input_shape=(10,50),return_sequences=True)) #hidden state: 64 dim\n",
    "model.add(Dropout(0.4))\n",
    "model.add(LSTM(64,input_shape=(10,50), return_sequences=False))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(5))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 105 samples, validate on 27 samples\n",
      "Epoch 1/40\n",
      "105/105 [==============================] - 1s 9ms/step - loss: 1.5876 - acc: 0.2571 - val_loss: 1.6177 - val_acc: 0.1852\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.61768, saving model to best_model.h5\n",
      "Epoch 2/40\n",
      "105/105 [==============================] - 0s 529us/step - loss: 1.5314 - acc: 0.3238 - val_loss: 1.6585 - val_acc: 0.2963\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.61768\n",
      "Epoch 3/40\n",
      "105/105 [==============================] - 0s 672us/step - loss: 1.4945 - acc: 0.3429 - val_loss: 1.6792 - val_acc: 0.2222\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.61768\n",
      "Epoch 4/40\n",
      "105/105 [==============================] - 0s 551us/step - loss: 1.4661 - acc: 0.3714 - val_loss: 1.6625 - val_acc: 0.2222\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.61768\n",
      "Epoch 5/40\n",
      "105/105 [==============================] - 0s 956us/step - loss: 1.4012 - acc: 0.4190 - val_loss: 1.6090 - val_acc: 0.1852\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.61768 to 1.60899, saving model to best_model.h5\n",
      "Epoch 6/40\n",
      "105/105 [==============================] - 0s 574us/step - loss: 1.3755 - acc: 0.4000 - val_loss: 1.5418 - val_acc: 0.2222\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.60899 to 1.54177, saving model to best_model.h5\n",
      "Epoch 7/40\n",
      "105/105 [==============================] - 0s 617us/step - loss: 1.3142 - acc: 0.4857 - val_loss: 1.4655 - val_acc: 0.2963\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.54177 to 1.46553, saving model to best_model.h5\n",
      "Epoch 8/40\n",
      "105/105 [==============================] - 0s 770us/step - loss: 1.2251 - acc: 0.5524 - val_loss: 1.3675 - val_acc: 0.4074\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.46553 to 1.36747, saving model to best_model.h5\n",
      "Epoch 9/40\n",
      "105/105 [==============================] - 0s 590us/step - loss: 1.1518 - acc: 0.5810 - val_loss: 1.3275 - val_acc: 0.3704\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.36747 to 1.32752, saving model to best_model.h5\n",
      "Epoch 10/40\n",
      "105/105 [==============================] - 0s 584us/step - loss: 1.0480 - acc: 0.6000 - val_loss: 1.3779 - val_acc: 0.3704\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.32752\n",
      "Epoch 11/40\n",
      "105/105 [==============================] - 0s 689us/step - loss: 0.9343 - acc: 0.6476 - val_loss: 1.3410 - val_acc: 0.4444\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.32752\n",
      "Epoch 12/40\n",
      "105/105 [==============================] - 0s 580us/step - loss: 0.8433 - acc: 0.7238 - val_loss: 1.2717 - val_acc: 0.5185\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.32752 to 1.27169, saving model to best_model.h5\n",
      "Epoch 13/40\n",
      "105/105 [==============================] - 0s 518us/step - loss: 0.8054 - acc: 0.7143 - val_loss: 1.2474 - val_acc: 0.5556\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.27169 to 1.24738, saving model to best_model.h5\n",
      "Epoch 14/40\n",
      "105/105 [==============================] - 0s 713us/step - loss: 0.7208 - acc: 0.7333 - val_loss: 1.3253 - val_acc: 0.4815\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.24738\n",
      "Epoch 15/40\n",
      "105/105 [==============================] - 0s 696us/step - loss: 0.6575 - acc: 0.7333 - val_loss: 1.3249 - val_acc: 0.5185\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.24738\n",
      "Epoch 16/40\n",
      "105/105 [==============================] - 0s 964us/step - loss: 0.5818 - acc: 0.7905 - val_loss: 1.1242 - val_acc: 0.5926\n",
      "\n",
      "Epoch 00016: val_loss improved from 1.24738 to 1.12419, saving model to best_model.h5\n",
      "Epoch 17/40\n",
      "105/105 [==============================] - 0s 600us/step - loss: 0.6440 - acc: 0.7714 - val_loss: 0.9099 - val_acc: 0.7037\n",
      "\n",
      "Epoch 00017: val_loss improved from 1.12419 to 0.90987, saving model to best_model.h5\n",
      "Epoch 18/40\n",
      "105/105 [==============================] - 0s 555us/step - loss: 0.5117 - acc: 0.8381 - val_loss: 0.9997 - val_acc: 0.5926\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.90987\n",
      "Epoch 19/40\n",
      "105/105 [==============================] - 0s 584us/step - loss: 0.4319 - acc: 0.8476 - val_loss: 1.1607 - val_acc: 0.6296\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.90987\n",
      "Epoch 20/40\n",
      "105/105 [==============================] - 0s 695us/step - loss: 0.3854 - acc: 0.8381 - val_loss: 1.0874 - val_acc: 0.7037\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.90987\n",
      "Epoch 21/40\n",
      "105/105 [==============================] - 0s 697us/step - loss: 0.3552 - acc: 0.8571 - val_loss: 1.0247 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.90987\n",
      "Epoch 22/40\n",
      "105/105 [==============================] - 0s 592us/step - loss: 0.3765 - acc: 0.8667 - val_loss: 0.9538 - val_acc: 0.7037\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.90987\n",
      "Epoch 23/40\n",
      "105/105 [==============================] - 0s 569us/step - loss: 0.3505 - acc: 0.8857 - val_loss: 1.0382 - val_acc: 0.7407\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.90987\n",
      "Epoch 24/40\n",
      "105/105 [==============================] - 0s 587us/step - loss: 0.3477 - acc: 0.8857 - val_loss: 0.8481 - val_acc: 0.7407\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.90987 to 0.84813, saving model to best_model.h5\n",
      "Epoch 25/40\n",
      "105/105 [==============================] - 0s 513us/step - loss: 0.2815 - acc: 0.9048 - val_loss: 0.7870 - val_acc: 0.7037\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.84813 to 0.78700, saving model to best_model.h5\n",
      "Epoch 26/40\n",
      "105/105 [==============================] - 0s 615us/step - loss: 0.2437 - acc: 0.9333 - val_loss: 0.9357 - val_acc: 0.7407\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.78700\n",
      "Epoch 27/40\n",
      "105/105 [==============================] - 0s 663us/step - loss: 0.2478 - acc: 0.9333 - val_loss: 0.7671 - val_acc: 0.7407\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.78700 to 0.76707, saving model to best_model.h5\n",
      "Epoch 28/40\n",
      "105/105 [==============================] - 0s 576us/step - loss: 0.2630 - acc: 0.8952 - val_loss: 1.1014 - val_acc: 0.6296\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.76707\n",
      "Epoch 29/40\n",
      "105/105 [==============================] - 0s 582us/step - loss: 0.2787 - acc: 0.8762 - val_loss: 0.9654 - val_acc: 0.7407\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.76707\n",
      "Epoch 30/40\n",
      "105/105 [==============================] - 0s 566us/step - loss: 0.2782 - acc: 0.8857 - val_loss: 0.9896 - val_acc: 0.7407\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.76707\n",
      "Epoch 31/40\n",
      "105/105 [==============================] - 0s 700us/step - loss: 0.1701 - acc: 0.9429 - val_loss: 0.8382 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.76707\n",
      "Epoch 32/40\n",
      "105/105 [==============================] - 0s 592us/step - loss: 0.2028 - acc: 0.9238 - val_loss: 0.7693 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.76707\n",
      "Epoch 33/40\n",
      "105/105 [==============================] - 0s 505us/step - loss: 0.1363 - acc: 0.9810 - val_loss: 0.7719 - val_acc: 0.7778\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.76707\n",
      "Epoch 34/40\n",
      "105/105 [==============================] - 0s 655us/step - loss: 0.0919 - acc: 0.9905 - val_loss: 0.8498 - val_acc: 0.7778\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.76707\n",
      "Epoch 35/40\n",
      "105/105 [==============================] - 0s 598us/step - loss: 0.1035 - acc: 0.9905 - val_loss: 0.8121 - val_acc: 0.7778\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.76707\n",
      "Epoch 36/40\n",
      "105/105 [==============================] - 0s 605us/step - loss: 0.0924 - acc: 0.9905 - val_loss: 0.7924 - val_acc: 0.7407\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.76707\n",
      "Epoch 37/40\n",
      "105/105 [==============================] - 0s 611us/step - loss: 0.0946 - acc: 0.9619 - val_loss: 0.8902 - val_acc: 0.7407\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.76707\n",
      "Epoch 38/40\n",
      "105/105 [==============================] - 0s 601us/step - loss: 0.1196 - acc: 0.9619 - val_loss: 1.0257 - val_acc: 0.7037\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.76707\n",
      "Epoch 39/40\n",
      "105/105 [==============================] - 0s 602us/step - loss: 0.2212 - acc: 0.9333 - val_loss: 1.1499 - val_acc: 0.7037\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.76707\n",
      "Epoch 40/40\n",
      "105/105 [==============================] - 0s 626us/step - loss: 0.1558 - acc: 0.9429 - val_loss: 1.2853 - val_acc: 0.5926\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.76707\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "checkpt = ModelCheckpoint(\"best_model.h5\", monitor='val_loss', verbose=True, save_best_only=True)\n",
    "earlystop = EarlyStopping(monitor='val_acc', patience=10)\n",
    "\n",
    "hist = model.fit(embed_matrix_train,YT,batch_size=32,epochs=40,shuffle=True,validation_split=0.2, callbacks=[checkpt, earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 3 2 2 2 2 1 2 4 2 1 2 0 2 1 3 2 2 3 2 0 0 4 2 3 1 2 0 1 2 0 1 0 2 0 1 2\n",
      " 3 4 2 1 0 0 1 2 2 2 2 0 1 1 0 3 2 3 0]\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict_classes(embed_matrix_test)\n",
    "\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56/56 [==============================] - 0s 387us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.7502823386873518, 0.5714285969734192]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(embed_matrix_test,Yt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I want to eat\n",
      "üç¥\n",
      "üç¥\n",
      "he did not answer\n",
      "üòì\n",
      "üòì\n",
      "he got a raise\n",
      "üòÅ\n",
      "üòÅ\n",
      "she got me a present\n",
      "‚ù§Ô∏è\n",
      "üòÅ\n",
      "ha ha ha it was so funny\n",
      "üòÅ\n",
      "üòÅ\n",
      "he is a good friend\n",
      "‚ù§Ô∏è\n",
      "üòÅ\n",
      "I am upset\n",
      "‚ù§Ô∏è\n",
      "‚öæ\n",
      "We had such a lovely dinner tonight\n",
      "‚ù§Ô∏è\n",
      "üòÅ\n",
      "where is the food\n",
      "üç¥\n",
      "üç¥\n",
      "Stop making this joke ha ha ha\n",
      "üòÅ\n",
      "üòÅ\n",
      "where is the ball\n",
      "‚öæ\n",
      "‚öæ\n",
      "work is hard\n",
      "üòì\n",
      "üòÅ\n",
      "This girl is messing with me\n",
      "üòì\n",
      "‚ù§Ô∏è\n",
      "are you serious ha ha\n",
      "üòÅ\n",
      "üòÅ\n",
      "Let us go play baseball\n",
      "‚öæ\n",
      "‚öæ\n",
      "This stupid grader is not working\n",
      "üòì\n",
      "üòì\n",
      "work is horrible\n",
      "üòì\n",
      "üòÅ\n",
      "Congratulation for having a baby\n",
      "üòÅ\n",
      "üòÅ\n",
      "stop messing around\n",
      "üòì\n",
      "üòì\n",
      "any suggestions for dinner\n",
      "üç¥\n",
      "üòÅ\n",
      "I love taking breaks\n",
      "‚ù§Ô∏è\n",
      "‚ù§Ô∏è\n",
      "you brighten my day\n",
      "üòÅ\n",
      "‚ù§Ô∏è\n",
      "I boiled rice\n",
      "üç¥\n",
      "üç¥\n",
      "she is a bully\n",
      "üòì\n",
      "üòÅ\n",
      "Why are you feeling bad\n",
      "üòì\n",
      "üòì\n",
      "I am upset\n",
      "üòì\n",
      "‚öæ\n",
      "I worked during my birthday\n",
      "üòì\n",
      "üòÅ\n",
      "My grandmother is the love of my life\n",
      "‚ù§Ô∏è\n",
      "‚ù§Ô∏è\n",
      "enjoy your break\n",
      "üòÅ\n",
      "‚öæ\n",
      "valentine day is near\n",
      "‚ù§Ô∏è\n",
      "üòÅ\n"
     ]
    }
   ],
   "source": [
    "for i in range(30):\n",
    "    print(' '.join(Xt[i]))\n",
    "    print(emoji.emojize(emoji_dictionary[str(np.argmax(Yt[i]))]))\n",
    "    print(emoji.emojize(emoji_dictionary[str(pred[i])]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Django application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"model.json\", \"w\") as file:\n",
    "    file.write(model.to_json())\n",
    "model.save_weights(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"model.json\", \"r\") as file:\n",
    "    model=model_from_json(file.read())\n",
    "model.load_weights(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "test_str=\"hello how are you\"\n",
    "X = pd.Series(test_str)\n",
    "print(type(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOutputEmbeddings(X):\n",
    "    \n",
    "#     embedding_matrix_output = np.zeros((X.shape[0],10,50))\n",
    "    \n",
    "#     for ix in range(X.shape[0]):\n",
    "#         X[ix] = X[ix].split()\n",
    "#         for jx in range(len(X[ix])):\n",
    "#             #go to every word in current(ix) sentence\n",
    "#             embedding_matrix_output[ix][jx] = embeddings[X[ix][jx].lower()]\n",
    "            \n",
    "    \n",
    "    X = X.split()\n",
    "    embedding_matrix_output = np.zeros((1,10,50))\n",
    "    for jx in range(len(X)):\n",
    "        #go to every word in current(ix) sentence\n",
    "        embedding_matrix_output[0][jx] = embeddings[X[jx].lower()]\n",
    "            \n",
    "    return embedding_matrix_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_X = getOutputEmbeddings(test_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = model.predict_classes(emb_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
